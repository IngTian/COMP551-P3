{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rmMAd8pu2kHT"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmMAd8pu2kHT"
      },
      "source": [
        "# **README**\n",
        "---\n",
        "\n",
        "## How do we run tests?\n",
        "In practice, we run experiments and gather results locally because the colab runtime can disconnect from time to time. We save models as `.pt` files and the accuracy records as `.json` files under the `out` folder.\n",
        "\n",
        "## The file structure?\n",
        "```Text\n",
        "├── dataset\n",
        "│   ├── images_l.pkl\n",
        "│   ├── images_test.pkl\n",
        "│   ├── images_ul.pkl\n",
        "│   └── labels_l.pkl\n",
        "├── init.py\n",
        "├── vgg16_vanilla.json\n",
        "├── p3.ipynb # This is where you should have your colab file.\n",
        "├── model\n",
        "│   ├── AlexNetVanilla.py\n",
        "│   ├── Baseline.py\n",
        "│   ├── VGG16Vanilla.py\n",
        "│   ├── VGG16_Deeper.py\n",
        "│   ├── VGG16_Delete_Tail.py\n",
        "│   ├── VGG16_Half_Width.py\n",
        "│   ├── VGG16_Higher_MaxPooling.py\n",
        "│   ├── VGG16_Higher_MaxPooling_Leaky.py\n",
        "│   └── __init__.py\n",
        "├── out\n",
        "│   ├── records.json # The experiment recrods.\n",
        "│   └── models\n",
        "│       └── ...      # Various saved models.\n",
        "├── out1 # For EM Records.\n",
        "│   └── ...\n",
        "├── requirements.txt\n",
        "└── utils\n",
        "    └── __init__.py\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPhdcDpibG1Q"
      },
      "source": [
        "## Setting up the Environment\n",
        "\n",
        "To execute the following codes, we need to set up the environment first, including installing python dependencies, downloading datasets, and so forth.\n",
        "\n",
        "Luckily, we have written a script for you, as in `init.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cFNFBoHdY6g",
        "outputId": "5dd135f9-9040-4c8b-944a-29a26fcdb88c"
      },
      "source": [
        "!python init.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INSTALLING DEPENDENCIES...\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.2 which is incompatible.\n",
            "moviepy 0.2.3.5 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.4.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.27.0 which is incompatible.\n",
            "google-colab 1.0.0 requires notebook~=5.3.0; python_version >= \"3.0\", but you have notebook 6.4.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.1 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.0.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "CREATING NECESSARY FOLDERS...\n",
            "DOWNLOADING DATASETS...\n",
            "100% 99.0M/99.0M [00:00<00:00, 156MB/s]\n",
            "100% 198M/198M [00:01<00:00, 144MB/s]\n",
            "100% 197M/197M [00:01<00:00, 144MB/s]\n",
            "100% 141k/141k [00:00<00:00, 85.3MB/s]\n",
            "PREPARE DATASETS...\n",
            "tcmalloc: large alloc 1073750016 bytes == 0x564be1968000 @  0x7f9cb4e9b2a4 0x564b940da4cc 0x564b9424093a 0x564b940dd46c 0x564b941cee1d 0x564b94150e99 0x564b940deafa 0x564b9414cc0d 0x564b9414b9ee 0x564b940debda 0x564b9414cc0d 0x564b9414b9ee 0x564b940debda 0x564b9414cc0d 0x564b9401dd14 0x564b9414dfe4 0x564b9414b9ee 0x564b940debda 0x564b94150d00 0x564b9414b9ee 0x564b9414b6f3 0x564b942154c2 0x564b9421583d 0x564b942156e6 0x564b941ed163 0x564b941ece0c 0x7f9cb3c84bf7 0x564b941eccea\n",
            "DONE(*¯︶¯*)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7boezUFHyDzY"
      },
      "source": [
        "# Running tests with a Specific Model.\n",
        "---\n",
        "\n",
        "In this study, we have encapsulated common utils under the `utils` module. Also, we have defined a general model tester in `model/__init__.py`. Simply passing the desired model into the tester, and it shall conduct experiments, record training and validation accuracies each epoch, and save intermediate models along the way. \n",
        "\n",
        "Here, we only provide you with a demo, using `VGG16Vanilla.py` from `model`.\n",
        "\n",
        "The code structure is modularized and thus easy to manipulate. Please take notice of the following code snippets.\n",
        "```python\n",
        "tester = ModelTester(\n",
        "    read_data(Path(DATASET_PATH)),\n",
        "    Net,\n",
        "    preprocesses=[]\n",
        ")\n",
        "\n",
        "training_options = {\n",
        "    \"epochs\": 50,\n",
        "    \"optimizer\": SGD,\n",
        "    \"optimizer_options\": {\n",
        "        \"lr\": 0.0005,\n",
        "        # \"betas\": (0.9, 0.99),\n",
        "        # \"eps\": 1e-8,\n",
        "        \"momentum\": 0.99\n",
        "    },\n",
        "    \"verbose\": False,\n",
        "    \"model_save_folder\": OUTPUT_MODELS_PATH\n",
        "}\n",
        "\n",
        "# Make tests.\n",
        "# make_test_predict(Path(\"out\") / \"vgg956.pt\", Path(\"out\") / \"test.csv\", tester)\n",
        "\n",
        "# Train model.\n",
        "train_model(tester, Path(\"out\") / \"models\", Path(\"out\") / \"records.json\", training_options)\n",
        "```\n",
        "\n",
        "The training options are parameters passed onto the model tester. For a full reference of available parameters, navigate to the ModelTester class in `model/__init__.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "Q8varacDyCkI",
        "outputId": "66d3e9cc-b310-48c0-a901-f5a21336b4bb"
      },
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from model import ModelTester\n",
        "from model.VGG16Vanilla import Net # Here you pick your model.\n",
        "from utils import RawData, DataType, Data, preprocess_de_noise\n",
        "import pickle\n",
        "from simple_chalk import chalk\n",
        "import json\n",
        "import os\n",
        "from torch.optim import Adam, SGD\n",
        "from typing import Dict, Any\n",
        "import pandas as pd\n",
        "\n",
        "OUTPUT_PATH = Path(\"./out\")\n",
        "OUTPUT_MODELS_PATH = OUTPUT_PATH / \"models\"\n",
        "OUTPUT_RECORDS_PATH = OUTPUT_PATH / \"records.json\"\n",
        "DATASET_PATH = Path(\"./dataset\")\n",
        "\n",
        "\n",
        "def read_data(path: Path) -> RawData:\n",
        "    \"\"\"\n",
        "    Read data from the specified data set folder.\n",
        "    :param path:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    training_x_path = path / \"images_l.pkl\"\n",
        "    training_label_path = path / \"labels_l.pkl\"\n",
        "    training_unlabeled_x_path = path / \"images_ul.pkl\"\n",
        "    test_path = path / \"images_test.pkl\"\n",
        "\n",
        "    with open(training_x_path, 'rb') as f:\n",
        "        training_x = pickle.load(f)\n",
        "\n",
        "    with open(training_label_path, 'rb') as f:\n",
        "        training_label = pickle.load(f)\n",
        "\n",
        "    with open(training_unlabeled_x_path, 'rb') as f:\n",
        "        training_unlabeled = pickle.load(f)\n",
        "\n",
        "    with open(test_path, 'rb') as f:\n",
        "        test = pickle.load(f)\n",
        "\n",
        "    validation_x, validation_y = training_x[:1000], training_label[:1000]\n",
        "\n",
        "    training_labeled = Data(training_x[1000:], training_label[1000:], DataType.LABELED_TRAINING)\n",
        "    training_unlabeled = Data(training_unlabeled, None, DataType.UN_LABELED_TRAINING)\n",
        "    test = Data(test, None, DataType.TEST)\n",
        "    validation = Data(validation_x, validation_y, DataType.VALIDATION)\n",
        "\n",
        "    result = RawData()\n",
        "    result.labeled_training = training_labeled\n",
        "    result.unlabeled_training = training_unlabeled\n",
        "    result.test = test\n",
        "    result.validation = validation\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def make_test_predict(\n",
        "        model_path: Path,\n",
        "        csv_result_path: Path,\n",
        "        container: ModelTester\n",
        ") -> None:\n",
        "    print(f'{chalk.bold(\"-\" * 25 + \"START TESTING\" + \"-\" * 25)}')\n",
        "    # Load the trained model.\n",
        "    container.load(model_path)\n",
        "    result = container.test().detach().cpu().numpy().astype(int)\n",
        "\n",
        "    # Convert the numpy into CSV format.\n",
        "    result = result.astype(bytearray)\n",
        "    copy = []\n",
        "    for i in range(len(result)):\n",
        "        copy.append(\"\".join(map(lambda k: str(k), result[i])))\n",
        "    result = np.array(copy)\n",
        "    index = np.linspace(0, len(result) - 1, num=len(result), dtype=int).transpose()\n",
        "    result = np.append(index[:, None], result[:, None], axis=1)\n",
        "    frame = pd.DataFrame(result)\n",
        "    frame.columns = [\"# ID\", \"Category\"]\n",
        "\n",
        "    # Write the CSV file.\n",
        "    frame.to_csv(csv_result_path.absolute(), index=False)\n",
        "    print(f'{chalk.bold(\"-\" * 25 + \"TESTING COMPLETED\" + \"-\" * 25)}')\n",
        "\n",
        "\n",
        "def train_model(\n",
        "        container: ModelTester,\n",
        "        output_models_path: Path,\n",
        "        output_records_path: Path,\n",
        "        training_options: Dict[str, Any]\n",
        ") -> None:\n",
        "    print(f'{chalk.bold(\"-\" * 25 + \"START TRAINING\" + \"-\" * 25)}')\n",
        "\n",
        "    # Create the folder if the folder does not exist.\n",
        "    if not output_models_path.exists():\n",
        "        os.makedirs(output_models_path.absolute())\n",
        "\n",
        "    training_records = container.train(**training_options)\n",
        "    print(f'{chalk.bold(\"-\" * 25 + \"TRAINING COMPLETED\" + \"-\" * 25)}')\n",
        "\n",
        "    # Save training records.\n",
        "    with open(output_records_path, 'w') as output_file:\n",
        "        json.dump(training_records, output_file)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tester = ModelTester(\n",
        "        read_data(Path(DATASET_PATH)),\n",
        "        Net,\n",
        "        preprocesses=[]\n",
        "    )\n",
        "\n",
        "    training_options = {\n",
        "        \"epochs\": 50,\n",
        "        \"optimizer\": SGD,\n",
        "        \"optimizer_options\": {\n",
        "            \"lr\": 0.0005,\n",
        "            # \"betas\": (0.9, 0.99),\n",
        "            # \"eps\": 1e-8,\n",
        "            \"momentum\": 0.99\n",
        "        },\n",
        "        \"verbose\": False,\n",
        "        \"model_save_folder\": OUTPUT_MODELS_PATH\n",
        "    }\n",
        "\n",
        "    # Make tests.\n",
        "    # make_test_predict(Path(\"out\") / \"vgg956.pt\", Path(\"out\") / \"test.csv\", tester)\n",
        "\n",
        "    # Train model.w\n",
        "    train_model(tester, Path(\"out\") / \"models\", Path(\"out\") / \"records.json\", training_options)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mCREATED MODEL TESTER\u001b[0m\n",
            "DEVICES USED           : cuda\n",
            "# OF LABELED TRAINING  : 29000\n",
            "# OF UNLABELED TRAINING: 30000\n",
            "# OF VALIDATION        : 1000\n",
            "# OF TEST              : 15000\n",
            "\u001b[1m-------------------------START TRAINING-------------------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-94238912082b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Train model.w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"records.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-94238912082b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(container, output_models_path, output_records_path, training_options)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_models_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mtraining_records\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtraining_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{chalk.bold(\"-\" * 25 + \"TRAINING COMPLETED\" + \"-\" * 25)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/__init__.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, epochs_record, records_load_rate, batch_size, loss_function, loss_function_options, optimizer, optimizer_options, verbose, model_save_folder)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__trained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCuQX5iHyuNg"
      },
      "source": [
        "# Expectation Maximum\n",
        "---\n",
        "\n",
        "Here, we present how we do the EM algorithm. Generally speaking, it is analogous to what we have done before, yet there are minor differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehlS9DJfyuvm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "6f70932e-004c-4029-a361-2d776a69cc29"
      },
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from model import ModelTester\n",
        "from model.VGG16_Higher_MaxPooling_Leaky import Net\n",
        "from utils import RawData, DataType, Data, preprocess_de_noise\n",
        "import pickle\n",
        "from simple_chalk import chalk\n",
        "import json\n",
        "import os\n",
        "from torch.optim import Adam, SGD\n",
        "from typing import Dict, Any\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# OUTPUT_PATH = Path(\"./out\")\n",
        "# OUTPUT_MODELS_PATH = OUTPUT_PATH / \"models\"\n",
        "# OUTPUT_RECORDS_PATH = OUTPUT_PATH / \"records.json\"\n",
        "DATASET_PATH = Path(\"./dataset\")\n",
        "\n",
        "\n",
        "def read_data(path: Path) -> RawData:\n",
        "    \"\"\"\n",
        "    Read data from the specified data set folder.\n",
        "    :param path:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    training_x_path = path / \"images_l.pkl\"\n",
        "    training_label_path = path / \"labels_l.pkl\"\n",
        "    training_unlabeled_x_path = path / \"images_ul.pkl\"\n",
        "    test_path = path / \"images_test.pkl\"\n",
        "\n",
        "    with open(training_x_path, 'rb') as f:\n",
        "        training_x = pickle.load(f)\n",
        "\n",
        "    with open(training_label_path, 'rb') as f:\n",
        "        training_label = pickle.load(f)\n",
        "\n",
        "    with open(training_unlabeled_x_path, 'rb') as f:\n",
        "        training_unlabeled = pickle.load(f)\n",
        "\n",
        "    with open(test_path, 'rb') as f:\n",
        "        test = pickle.load(f)\n",
        "\n",
        "    validation_x, validation_y = training_x[:1000], training_label[:1000]\n",
        "\n",
        "    training_labeled = Data(training_x[1000:], training_label[1000:], DataType.LABELED_TRAINING)\n",
        "    training_unlabeled = Data(training_unlabeled, None, DataType.UN_LABELED_TRAINING)\n",
        "    test = Data(test, None, DataType.TEST)\n",
        "    validation = Data(validation_x, validation_y, DataType.VALIDATION)\n",
        "\n",
        "    result = RawData()\n",
        "    result.labeled_training = training_labeled\n",
        "    result.unlabeled_training = training_unlabeled\n",
        "    result.test = test\n",
        "    result.validation = validation\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_random_label(labels, num):\n",
        "    \"\"\"\n",
        "    assign random labels for unlabeled images\n",
        "    :param labels: training labels\n",
        "    :param num:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    index_range = np.arange(0, labels.shape[0])\n",
        "    rand_indices = np.random.choice(index_range, num, replace=False)\n",
        "    return labels[rand_indices]\n",
        "\n",
        "\n",
        "def prepare_data(training_x, training_label, training_unlabeled, test, num) -> RawData:\n",
        "    \"\"\"\n",
        "    :param path:\n",
        "    :param num: number of unlabled data to use for training\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    validation_x, validation_y = training_x[:1000], training_label[:1000]\n",
        "    training_labeled = Data(training_x[1000:], training_label[1000:], DataType.LABELED_TRAINING)\n",
        "    training_unlabeled = Data(training_unlabeled[:num], None, DataType.UN_LABELED_TRAINING)\n",
        "    test = Data(test, None, DataType.TEST)\n",
        "    validation = Data(validation_x, validation_y, DataType.VALIDATION)\n",
        "    result = RawData()\n",
        "    result.labeled_training = training_labeled\n",
        "    result.unlabeled_training = training_unlabeled\n",
        "    result.test = test\n",
        "    result.validation = validation\n",
        "    return result\n",
        "\n",
        "\n",
        "def train_model(\n",
        "        container: ModelTester,\n",
        "        output_models_path: Path,\n",
        "        output_records_path: Path,\n",
        "        training_options: Dict[str, Any]\n",
        ") -> None:\n",
        "    print(f'{chalk.bold(\"-\" * 25 + \"START TRAINING\" + \"-\" * 25)}')\n",
        "\n",
        "    # Create the folder if the folder does not exist.\n",
        "    if not output_models_path.exists():\n",
        "        os.makedirs(output_models_path.absolute())\n",
        "\n",
        "    training_records = container.train(**training_options)\n",
        "    print(f'{chalk.bold(\"-\" * 25 + \"TRAINING COMPLETED\" + \"-\" * 25)}')\n",
        "\n",
        "    # Save training records.\n",
        "    with open(output_records_path, 'w') as output_file:\n",
        "        json.dump(training_records, output_file)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    path = DATASET_PATH\n",
        "    training_x_path = path / \"images_l.pkl\"\n",
        "    training_label_path = path / \"labels_l.pkl\"\n",
        "    training_unlabeled_x_path = path / \"images_ul.pkl\"\n",
        "    test_path = path / \"images_test.pkl\"\n",
        "\n",
        "    with open(training_x_path, 'rb') as f:\n",
        "        training_x = pickle.load(f)\n",
        "\n",
        "    with open(training_label_path, 'rb') as f:\n",
        "        training_label = pickle.load(f)\n",
        "\n",
        "    with open(training_unlabeled_x_path, 'rb') as f:\n",
        "        training_unlabeled = pickle.load(f)\n",
        "\n",
        "    with open(test_path, 'rb') as f:\n",
        "        test = pickle.load(f)\n",
        "\n",
        "    num = 10000\n",
        "    random_label = get_random_label(training_label, num)\n",
        "    training_x = np.concatenate((training_x, training_unlabeled[:num]), axis=0)\n",
        "    training_initial = np.concatenate((training_label, random_label[:num]), axis=0)\n",
        "\n",
        "    result = prepare_data(training_x, training_initial, training_unlabeled, test, num)\n",
        "\n",
        "    for i in range(20):\n",
        "        print(f\"iteration {i + 1}\")\n",
        "        tester = ModelTester(\n",
        "            result,\n",
        "            Net,\n",
        "            preprocesses=[]\n",
        "        )\n",
        "\n",
        "        training_options = {\n",
        "            \"epochs\": 20,\n",
        "            \"optimizer\": SGD,\n",
        "            \"optimizer_options\": {\n",
        "                \"lr\": 0.0005,\n",
        "                # \"betas\": (0.9, 0.99),\n",
        "                # \"eps\": 1e-8,\n",
        "                \"momentum\": 0.99\n",
        "            },\n",
        "            \"verbose\": False,\n",
        "            \"model_save_folder\": Path(f\"./out{i + 1}\")\n",
        "        }\n",
        "\n",
        "        output_model_path = Path(f\"out{i + 1}/models\")\n",
        "        output_record_path = Path(f\"out{i + 1}\") / \"records.json\"\n",
        "\n",
        "        train_model(tester, output_model_path, output_record_path, training_options)\n",
        "\n",
        "        with open(output_record_path, 'r') as j:\n",
        "            contents = json.loads(j.read())\n",
        "\n",
        "        best_index = 0\n",
        "        min_val_error = 100\n",
        "        for j in range(len(contents)):\n",
        "            cur_err = contents[j]['validation_error']\n",
        "            if cur_err < min_val_error:\n",
        "                min_val_error = cur_err\n",
        "                best_index = j\n",
        "        best_index += 1\n",
        "\n",
        "        # load the best  model\n",
        "        print('Load the best model', best_index)\n",
        "        tester.load(Path(f'./out{i + 1}') / f'epoch_{best_index}.pt')\n",
        "        # predict the labels for unlabeled data\n",
        "        predicted_labels = tester.predict_unlabeled().detach().numpy()\n",
        "        # update result\n",
        "        training_updated = np.concatenate((training_label, predicted_labels), axis=0)\n",
        "        result = prepare_data(training_x, training_updated, training_unlabeled, test, num)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1\n",
            "\u001b[1mCREATED MODEL TESTER\u001b[0m\n",
            "DEVICES USED           : cuda\n",
            "# OF LABELED TRAINING  : 39000\n",
            "# OF UNLABELED TRAINING: 10000\n",
            "# OF VALIDATION        : 1000\n",
            "# OF TEST              : 15000\n",
            "\u001b[1m-------------------------START TRAINING-------------------------\u001b[0m\n",
            "\u001b[1mCOMPLETED EPOCH: 1\u001b[0m \u001b[1mTRAINING ERROR RATE: \u001b[0m \u001b[91m94.8\u001b[0m% \u001b[1mVALIDATION ERROR RATE: \u001b[0m \u001b[91m93.5\u001b[0m%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dce3de02aca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0moutput_record_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"out{i + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"records.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_record_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_record_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-dce3de02aca1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(container, output_models_path, output_records_path, training_options)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_models_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtraining_records\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtraining_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{chalk.bold(\"-\" * 25 + \"TRAINING COMPLETED\" + \"-\" * 25)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/__init__.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, epochs_record, records_load_rate, batch_size, loss_function, loss_function_options, optimizer, optimizer_options, verbose, model_save_folder)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# Update weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mgradient_descent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/VGG16_Higher_MaxPooling_Leaky.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vpRoCDxZSvA"
      },
      "source": [
        "# Data Augmentation\n",
        "---\n",
        "\n",
        "The following code snippets show how we do data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "DZL4A19NZd1F",
        "outputId": "0c696bd4-7aa3-42dd-fa7d-692573d44782"
      },
      "source": [
        "from pathlib import Path\n",
        "from model import ModelTester\n",
        "from model.VGG16_Higher_MaxPooling_Leaky import Net\n",
        "from utils import RawData, DataType, Data, preprocess_de_noise, image_rotation\n",
        "import pickle\n",
        "from simple_chalk import chalk\n",
        "import json\n",
        "import os\n",
        "from torch.optim import Adam, SGD\n",
        "import numpy as np\n",
        "\n",
        "OUTPUT_PATH = Path(\"./out\")\n",
        "OUTPUT_MODELS_PATH = OUTPUT_PATH / \"models\"\n",
        "OUTPUT_RECORDS_PATH = OUTPUT_PATH / \"records.json\"\n",
        "DATASET_PATH = Path(\"./dataset\")\n",
        "\n",
        "\n",
        "def read_data(path: Path) -> RawData:\n",
        "    \"\"\"\n",
        "    Read data from the specified data set folder.\n",
        "    :param path:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    training_x_path = path / \"images_l.pkl\"\n",
        "    training_label_path = path / \"labels_l.pkl\"\n",
        "    training_unlabeled_x_path = path / \"images_ul.pkl\"\n",
        "    test_path = path / \"images_test.pkl\"\n",
        "\n",
        "    with open(training_x_path, 'rb') as f:\n",
        "        training_x = pickle.load(f)\n",
        "\n",
        "    with open(training_label_path, 'rb') as f:\n",
        "        training_label = pickle.load(f)\n",
        "\n",
        "    with open(training_unlabeled_x_path, 'rb') as f:\n",
        "        training_unlabeled = pickle.load(f)\n",
        "\n",
        "    with open(test_path, 'rb') as f:\n",
        "        test = pickle.load(f)\n",
        "\n",
        "    degrees = [15, 30, 0, -15, -30]\n",
        "    val_x = training_x[:1000]\n",
        "    val_y = training_label[:1000]\n",
        "    training_x = image_rotation(training_x[1000:], degrees)\n",
        "    training_label = np.tile(training_label[1000:], (len(degrees) + 1, 1))\n",
        "\n",
        "    validation_x, validation_y = val_x, val_y\n",
        "\n",
        "    training_labeled = Data(training_x, training_label, DataType.LABELED_TRAINING)\n",
        "    training_unlabeled = Data(training_unlabeled, None, DataType.UN_LABELED_TRAINING)\n",
        "    test = Data(test, None, DataType.TEST)\n",
        "    validation = Data(validation_x, validation_y, DataType.VALIDATION)\n",
        "\n",
        "    result = RawData()\n",
        "    result.labeled_training = training_labeled\n",
        "    result.unlabeled_training = training_unlabeled\n",
        "    result.test = test\n",
        "    result.validation = validation\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # result = read_data(Path(DATASET_PATH))\n",
        "\n",
        "    tester = ModelTester(\n",
        "        read_data(Path(DATASET_PATH)),\n",
        "        Net,\n",
        "        preprocesses=[]\n",
        "    )\n",
        "    print(f'{chalk.bold(\"-\" * 25 + \"START TRAINING\" + \"-\" * 25)}')\n",
        "\n",
        "    # Create the folder if the folder does not exist.\n",
        "    if not OUTPUT_MODELS_PATH.exists():\n",
        "        os.makedirs(OUTPUT_MODELS_PATH.absolute())\n",
        "\n",
        "    training_records = tester.train(\n",
        "        epochs=50,\n",
        "        optimizer=SGD,\n",
        "        optimizer_options={\n",
        "            \"lr\": 0.0005,\n",
        "            \"momentum\": 0.99\n",
        "        },\n",
        "        verbose=False,\n",
        "        model_save_folder=OUTPUT_MODELS_PATH\n",
        "    )\n",
        "    print(f'{chalk.bold(\"-\" * 25 + \"TRAINING COMPLETED\" + \"-\" * 25)}')\n",
        "\n",
        "    # Save training records.\n",
        "    with open(OUTPUT_RECORDS_PATH, 'w') as output_file:\n",
        "        json.dump(training_records, output_file)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mCREATED MODEL TESTER\u001b[0m\n",
            "DEVICES USED           : cuda\n",
            "# OF LABELED TRAINING  : 145000\n",
            "# OF UNLABELED TRAINING: 30000\n",
            "# OF VALIDATION        : 1000\n",
            "# OF TEST              : 15000\n",
            "\u001b[1m-------------------------START TRAINING-------------------------\u001b[0m\n",
            "\u001b[1mCOMPLETED EPOCH: 1\u001b[0m \u001b[1mTRAINING ERROR RATE: \u001b[0m \u001b[91m27.1\u001b[0m% \u001b[1mVALIDATION ERROR RATE: \u001b[0m \u001b[91m23.8\u001b[0m%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d19b2fd1498b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         },\n\u001b[1;32m     84\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mmodel_save_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_MODELS_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{chalk.bold(\"-\" * 25 + \"TRAINING COMPLETED\" + \"-\" * 25)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/__init__.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, epochs_record, records_load_rate, batch_size, loss_function, loss_function_options, optimizer, optimizer_options, verbose, model_save_folder)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__trained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqXrbs8BdubX"
      },
      "source": [
        "# Picture Drawing\n",
        "---\n",
        "\n",
        "The following code snippets show how we draw the pictures with `.json` files created by when training the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nCJE5xo9Gih"
      },
      "source": [
        "## Change the library for saving the graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "DcwJee7ayI1j",
        "outputId": "4733fd93-6fa2-4075-d47c-f3109e80f1de"
      },
      "source": [
        "pip install matplotlib==3.1.3"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matplotlib==3.1.3\n",
            "  Downloading matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.21.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib==3.1.3) (1.16.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.4.3\n",
            "    Uninstalling matplotlib-3.4.3:\n",
            "      Successfully uninstalled matplotlib-3.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.2 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.1.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7n0lNr-9Z2A"
      },
      "source": [
        "## Example of drawing the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Kr36P88wdubc",
        "outputId": "69691c5c-e338-485d-fba9-5ee0b80efe16"
      },
      "source": [
        "from utils import json_to_numpy, plot_accuracy_trends\n",
        "legend_list = [\"Training\", \"Validation\"]\n",
        "acc_list = []\n",
        "\n",
        "epoch_list, train_acc_list, val_acc_list = json_to_numpy(\"vgg16_vanilla.json\")\n",
        "acc_list.append(train_acc_list)\n",
        "acc_list.append(val_acc_list)\n",
        "\n",
        "plot_accuracy_trends(epoch_list, acc_list, legend_list, \"Vgg_16\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}